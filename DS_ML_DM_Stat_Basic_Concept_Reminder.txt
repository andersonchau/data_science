Learning Notes for reminder and concept intuition


=====================================================================================================================================


==========================================================================================================================
ML/DM difference :
-- use same technique ( SVM, LR, Logistic R ... )
ML - we program something (predict a model for future preduction) using data
DM - we use data to build model to create knowledge ( knowledge discovery)
==========================================================================================================================
========================================================================================================================
Statistics -- how to collect data, interpret data, reach conclusion about data. 
Descriptive Stat -- mean/var/skewness to discribe data, visualization 
Inferential Stat -- estimation , hypothesis testing
ML(Predictive modeling) vs Stat(Stat learning) -- use algo to model data vs studies of maths of model and goodness of fit.
Exploratory data analysis -- summarization and visualization of data. 
Data Mining -- finding patterns/relationship in data.

Error :
Generalization error: errors rate that a model worked on unseen data. i.e. test error
Standard error : Standard error of mean, 
RV :
A numerical variable, having it values comes in an associated probability.
==========================================================================================================================
Independent, Identically distributed(iid):
Independent --  different samples have no correlations , formal P(x and y) = P(x)*P(y)
Identically distributed -- have the same distribution 
==========================================================================================================================
Central Limit Theorem (proof omitted): 
When sample size is large enough, the sample means will comes in Normal distribution with (Population of any distribution)
sample mean = population mean 
and sample SD = PSD/sqrt(n)
==========================================================================================================================
Pearson coefficient :
-- -1 to 1, 1 large LINEAR relationship between 2 RV, 0 independent.
-- but easily affected by outliers. 
==========================================================================================================================
PCA : 
-- problem : too many features , we want to combine some features into one by linear combination
-- But we still want to maximize the variance of new feature,so that the one component still collects the most "uniqueness" from the data set.
( to minimize the reconstruction error ) 
-- in his case transformed vectors will lose the min. consistuent elements characteristics (compressed lesser other-dimension ) 
-- it is found by finding the project of "principle axis" of the data in features 
and features are projected into this axis to form the new feature. 
-- it can be proved that max var. is equivalent to finding max. eigenvalue and it associated eigenvector ( principal axis ). 

==========================================================================================================================
Greedy Algorithm : 
-- We have no algo to find an optimal solution, brute force is too costly. 
-- We define an objective(largest reduction in entropy, which we conform to and and make the best of it. 
-- Greedy Algorithm generally not finding optimal solution, but based on the objective
Dynamic programming is used with Greedy Algorithm to break down bigger problem into smaller problem and fix it. 

==========================================================================================================================

Shannon Entropy Concept ( for decision tree ID3、C4.5、C5.0) :
( ref : https://arxiv.org/abs/1405.2061)
How Entropy formula relates to certainty. 
-- Surpurise ( events of low probability ), 
(1) Measure the EXPECTED average min. amount of information (number of bits) used to store a distribution of event, 
to save bits, we generally use smaller number of bits to indicate higher change event (e.g. 01 ) and larger number 
of bits to denote smaller chance event (e.g. 00100101 ). This can be calculated by Shannon Entropy formula. 
(2) evenly distributed events(10*10%) (no surprise/uncertain) generally has highest entropy 
( we cannot do optimization to assign higher number of bits to lesser chance events ), more certain cases(80%,10%,10%..) use lesser 
bytes. 
=> Entropy formula measure the uncertainty of event distribution. => higher entropy, higher uncertainty 

How certainty relates to Decision Tree.
IG (Information Gain) => amount reduction in entropy => amount of uncertainty removed.
With this splitting, we are in a more certain position make decision.


Some Decision tree are the greedy algorithm aiming to minimize the largest entropy (greatest information gain) first. 
=> DT is to do splitting on the feature which provides highest promotion of certainty. 
e.g. P(C_1|A_1) = 0.4/P(C_2|A_1) = 0.6/P(C_1|A_2) = 0.4/P(C_2|A_2) = 0.6 
<-- less certain , even after answering this question, we do not gain much information. 

P(C_1|B_1) = 0.01,P(C_2|B_1) = 0.99,P(C_1|B_2) = 0.99,P(C_2|B_2) = 0.01 
=> We will choose Splitting on B instead of A first, and we probably will discard the splitting on A. 

e.g. features, M/F , Tall/Short, muscular/thin => play basketball 
M/F less IG , T/S highest IG, M/T middle IG
(same percentage of M/F player basketball,  short people generally wont play  )
Tree may be 
Short -> not player , Tall -> next 
Tall+Thin -> not player , Tall+muscular -> player 
M/F too low IG , not considered

Gini impurity (CART) , usage : similar to Entropy 
This is the probably of a class of object randomly put into the distribution, what is the probability of misclassification 
higher => more uncertain
in this case : 1-p1^2 - p2^2 ......  ,

==========================================================================================================================
https://www.jmp.com/en_hk/statistics-knowledge-portal/t-test/two-sample-t-test.html

Hypothesis Testing (with t-test,z-test,sign-test) :

H0(Null Hypothesis) - Assumption failed to be rejected
H1(Alternative Hypothesis) - Assumption rejected at some level significance 

p-value :
The probability that the sample gives such a (or more extreme) result, given the condition that H0 is true. 
It is tested against significant level (e.g. 95%/99% ) for Hypothesis testing 
p-value obtained by sample is used to compare against a critical value of a sig. level for H-Test
p-value<critical value => not sig. result , failed to reject H0
p-value>critical value => sig. result , reject H0
e.g. sample = 100 , mean = 25 min , p-value = P(mean > 25 min | H0 true )

Assume Sig. level = 95%
Type I Error : Incorrect rejection of a true H0, false positive 
Type II Error : H1 is in fact true but we failed to reject H0, false negative


T-test : ( sample size < 30 , or (unknown population var AND sample size large) or known normal distribution )
1-sample-test : test whether mean of single population = target value ( is mean this sample of this population = 30) 

2-sample-test : test whether means of 2 population are different ( does mean of height of female diff from mean of height of male )
Paired T : Test whether difference between 2 dependent = target value ( does mean of weight diff after taking weight loss pill )

python : ttest_rel(data1, data2) // from scipy.stats import ttest_rel

Z-test( assumed normal distribution , used when known population variance or sample size >= 30 )
1-sample-test: test whether sample mean =/= population mean 
2-sample-test: test wether means of 2 samples are different.

t-test use sample SD , z-test used population SD

ANOVA
one-way : H0: all sample independent distribution are equals , H1: one or more sample mean(s) is/are not equal
python : stat, p = f_oneway(data1, data2, data3) // from scipy.stats import f_oneway
Repeated Measures ANOVA Test : H0: aAll paired sample distributions are equal , H1: One or more paired sample distributions are not equal.
==========================================================================================================================

Chi square test (Goodness of fit) 
full example : https://stattrek.com/chi-square-test/goodness-of-fit.aspx
Given categorical variable , it is used in Hypothesis test whether the sample data consistent(H0) with a specified distribution or not (Ha)
e.g. Merchant claimed that the draw have 10% gold, 20% silver, 70% bronze coin , we have 2% gold, 8 % silver, 92% bronze coin in sample 
 
 ==========================================================================================================================

Chi square test (Independence ) :
full example : https://stattrek.com/chi-square-test/independence.aspx
-- applicable to X2 test apply to categorical variable, each sample size happens at least n>=5, sample is simple random sampleing 
-- case similar to GoF test, just to check whether 2 distribution are depenent or not. 

One-way Test : whether in a group of distribution , whether means are different by examining the variance.
ref : https://online.stat.psu.edu/stat500/lesson/10/10.1

==========================================================================================================================
Association Rule Mining , basket analysis : 
confidence  :
lift :
support :  
==========================================================================================================================
Maximum Likelihood Estimation (MLE):
When we have a set of sample data, we want to find the best parameter of a model (e.g. mean, standard deviation ) which is best fit to this 
observation ( sampled data). best chance (max. likehood) that fit this model.
==========================================================================================================================
Errors :
Standard Error : 
Generalization Error : in ML, Stat.L,  GE = measure of how accurate an algorithm to predict previously unseen data. sometimes = test error
It includes irreducible error (Noise), Bias : by models' too simple , Variance : model too complicated, captured too many noise in training data.
 
==========================================================================================================================
Unbias Estimator : 
==========================================================================================================================
Linear Discriminant Analysis :
==========================================================================================================================
Generative vs Discrminative Learning Model for classification  (ref : CS229 notes2 Generative ) 
D - example : Logistic Regression.
G - example : Naive Bayes Classifier , Gaussian Discriminant Analysis
suppose 2 classes y1, y2 cases, x be features
Discriminative : to classify y based on x <=> to see p(y1|x) or p(y2|x) is greater for hypothesis. 
Generative : Approach to find p(y|x), instead of finding p(y|x) directly , 
model p(x|y) and p(y) (or p(x,y)) (given known classes, observe the distribution of its features) ,then use  p(x|y)p(y)/p(x) to find p(y|x)
p(x) can be omitted because argmax y p(y|x) = argmax y p(x|y)p(y) = argmax y (p(x AND y))

which means : In the modeling process , if want to find max. p(y|x) 
( Note in here, the concept is very similar (in fact the same) to MLE for parameter estimation , but in fact here, we are having trying y =1/y=0 , variating the class instead of 
parameter variation )

it is the same as finding max value of (p(x AND y)) during our observation.

p(y|x) means given features, the distribution of p(y) which is h(x)
p(x|y) found by we have samples which is classified , we observe their features. 
y = elephant ,man, x = height 

What does "argmax y p(y|x) = argmax y p(x|y)p(y)" means ? 
e.g. 
for case where y = {0,1}  		
we find p(x|y=1)p(y=1) > p(x|y=0)p(y=0), then argmax y....  is 1 , 
same as when given x, we classify y = 1 because p(y=1|x) > p(y=0|x) { finding argmax y p(y|x)}

Assume we have a new case to classify 
we consider p(x1, . . . , x50000|y) ( some x's one , some x's zero ) 
= p(x1|y)p(x2|y, x1)p(x3|y, x1, x2)· · · p(x50000|y, x1, . . . , x49999) (by Bayes rule)
= p(x1|y)p(x2|y)p(x3|y)· · · p(x50000|y) (by Naive Bayes assumption)
=> classified y = argmax y p(y) p(xi|y)..... p(xn|y)


============================================================================================================================
Bayesian Statistics 
Bayesian Theorem : p(x,y) = p(y|x)p(x) = p(x|y)p(y)
Bayesian Learning : 
p(Theta | Data ) {Posterier}
= p(Data | Theta ){likelihood} * p(Theta) {prior} /p(Data) {Normalization}
A view : (https://www.stat.auckland.ac.nz/~brewer/stats331.pdf)
Prior : initial guess
Likelihood : given initial guess, we have this sample data
Then final estimation = Posterier = prior + likelihood update 
============================================================================================================================
Maximum likelihood estimation(MLE), maximimize the L(theta) = p(Data|Theta)  

Interpreting Likelihood function : 
L(theta) {or L(theta|X) }is defined as p(X|theta), the distribution of x (which is observed sample, note in classification samples 
notice in GLM MAP is used instead of MLE ) given the variation of parameters 
In interpreting L , we have to think in the context of parameter estimation, therefore it is the variation of theta
it is L(theta|x) because we are working based on the observed samples x. 


x is multivariate , and x1,... xn are independent, we have L(Theta) = p(x1|theta)*p(x2|theta).... p(xn|theata) , if every increasing, can apply
log likelihood.
We target to find theta that make the observed sample most likely (this theta is most probable for the observed data), i.e. to maximize p(Data|Theta)

============================================================================================================================
Gradient Descent In Practice (ref : Coursera StandfordOnline - ML)
--GD will be fast

=============================================================================================================================
Ensembling methods : (ref :cs229 ensemble)
good : decrease in var, better accuracy , free validation set (Out of Bag data), support missing value
bad : increase bias, hard to interpret , more expensive ,not additive. 

https://towardsdatascience.com/what-is-out-of-bag-oob-score-in-random-forest-a7fa23d710

-- It can be proved that variance can be reduced by "averaging error" 
-- by increasing n(number of models, but increase cost ), and decrease correlation of models), to de-correlate models : 
use diff algorithm(SVM,logistic) , use diff training set, Bagging , Boosting 

Bootstrap : to create multiple samples (size of full samples ) through replacement 
-- pro : got many different sample sets. Since we assume S = P, replacement can resemble duplication in P. 

Bagging ( not limited to DT )
-- By averaging (aggregrating ) the output of models, or voting for classification, we reduce variance with on p and M. 
-- reduced correlations term w.r.t. single sample(Bootstrap), reduced VAR by increasing number of models 
-- using bootstrap, on avg. only 2/3 of data is used for training for each tree, remaining data (out-of-bag data) can be used for test set.
(https://towardsdatascience.com/what-is-out-of-bag-oob-score-in-random-forest-a7fa23d710).
OOB error estimation can rougly give the generalization error, OOB erorr gives an equivalent result to LOOCV
-- If our test sample does not contain a feature, we can just exclude those model(tree) used that feature in split.


Boosting : 
-- Choose a weak learner first(prediction rate just barely > 50% ), create more stronger learners, then predict results using the averaging of learners.

example : Adaboost  https://blog.paperspace.com/adaboost-optimizer/ note the alpha variation and how alpha is applied to data
-- create stronger learners by increasing the weight of mis-classified data , then 
-- don't know why additive model => next model dependent on preivous model ( which will increase variance ).
"Each new weak learner is no longer independent of the previous models in the sequence, meaning that increasing
M leads to an increase in the risk of overfitting." -- just because the data weight change ? 

FASM (Forward Stagewise Additive Modeling)
-- use lost function L (e.g. residual function y-h(x)) to train the next weak learner
-- Adaboost is a special case of FASM
-- note it is an abstract model, not implementation like Adaboost. 

Gradient Boosting :



=============================================================================================================================
Support Vector Machine : (SVM Succinctly) 
First assume are linearly separable. 
Hyperplane : subspace with n-1 dimension, mathamatically : w.x+b, for simplicity , just let y = {-1,1}
General Idea : We find a hyperplane wich min. distance of data point to the plane (geometric margin ) is greatest. (***) , for all samples
f = y(w.x + b) , f : functional margin, w.x+b is the prediction , y is the actual sampled data, 
if prediction is correct => f +ve , otherwise f -ve 
w have to be normalized -> w/|w| for fair comparison
=> f = y((w/|w|).x+(b/|w|))

Function Margin vs Geomertric Margin
GM is just scaled version of FM by |w|, GM = FM/|w|
FM only tell whether properly classified (properly classified => +ve or missclassified -ve), GM can tell the the confidence.
FM is introduced to provide intuition to distance maximization ( thinking this way, FM is more like geometric, but in actual computation ,
we need GM for correctness of confidence. It is because can always scale up FM to increase the distance of data point to hyperplane, which is 
meaningless. ) (ref : https://stackoverflow.com/questions/20058036/svm-what-is-a-functional-margin) 

Simplified Derivation :
For a particular sample i (xi,yi)

Geometric Margin = min (ri) 
where ri = functional margin / |w| = yi( (w/|w|).xi + b/|w| )

Optimal separating Hyperplane (w,b) for data is the plane where GM is largest.

ie
maximize M subject to ri >= M for all i
 (w,b) 
It is finally a convex optimization problem : 
minimize 1/2 * |w|^2

subject to yi(w.xi)+b>=1 for all i



My Reference :
Books : 
Introduction to Statistical Learning 
SVM Succinctly ( step-by-step intro to SVM )
Elements of Statistical Learning (ISL is much easier, haven't started reading this yet)
Machine Learning, Tom Mitchell

Bookmarked University UG/PG DS courses :

http://cs229.stanford.edu/ -- ( the best , not pure ML : Sometimes mix with Stat. Learning / Bayesian Stat. )
http://cs109.github.io/2015/pages/videos.html  
http://web.stanford.edu/class/cs109/ -- first half parts are too easy, later part is good for understanding some concepts like Likelihood, Boosting.

CUHK Data Mining :
www1.se.cuhk.edu.hk/_hcheng/seg4630/index.html -- CUHK data mining courses, 
others (ECLT 5810 E-Commerce Data Mining Technique/
CMSC5724 Data Mining and Knowledge Discovery)

Data Mining seems to ousted by ML courses these years, but I think those materials are still very worth reading.

General Statistics (t-test,z-test,chi-square test,sign test,ANOVA)
https://stattrek.com/
https://online.stat.psu.edu/stat500/
Khan Academy

Linear Algebra / Matrix computation :
http://www.ee.cuhk.edu.hk/~wkma/engg5781/ -- ENGG 5781 Matrix Analysis and Computations 
( PSM, Least square , Matrix Diagonalization parts are very useful for understanding CS229 notes )



Online Bootcamp-type course :
https://www.coursera.org/learn/machine-learning -- ( Best for beginner , not maths intensive )
https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/ -- best how-to for python beginners
https://www.kaggle.com/learn/overview -- free courses, step-by-step practical tutorial. 

Python for DS : 
https://jakevdp.github.io/PythonDataScienceHandbook/
https://github.com/ageron/handson-ml
https://github.com/fengdu78/
Books : Python for Data Analysis

Dashboard 
Qlik Sense :  
I used QS in working, My comment :
-- the GUI is beautiful/professional and responsive, boss/businessmen would like it  
But 
-- association model is quite redudant in my opinion 
-- Weak ETL / data cleaning tools , Load script has to be written very complicated to support 
-- It is just a BI tools for data display , very weak integration with analytic tools of (ML,python) 

Learning Resources : 
-- "Mastering Qlik Sense" 
-- Udemy QS certificate course
-- QS official tutorial and newsgroup.

R

Other ML courses :
http://www.cs.cornell.edu/courses/cs4780/2018fa/page18/

=====================================================================================================================================
How Much maths do you need ?
-- you dont know , derivation of ML algorithms borrow many Maths from Stat/Optimization subjects. 
-- But Some (not All) Linear Algebra, Multivariate calculus are needed, especially on model evaluation( stat. learning )
-- just read when you need it. 
-- I am still not sure whether Convex Optimization (studied first few chapters of Boyd , just stopped )is needed.

Why Study DS/ML :
-- I like Applied Maths as well as programming.
-- I want to understand Modern AI that is changing the world
-- I think this is a skills requirement for an IT guy


Topics :  

Linear Regression, 
Logistic Regression, 
Support Vector Machine , 

K-Nearest Neighbour classifier , 
K-Means clustering 

Decision Tree:
General (Entropy, Gini based)

Ensembling : 
With Bagging (Random Forest)
With Boosting (AdaBoost, XGBoost)

Naive Bayes Classifier, 
Gradient Discriminant Analysis, 
Perceptron Learning,
Softmax Regression 
Gaussian Discriminant Analysis

EM Algorithm : 
Bias Variance Analysis 

Deep Learning : 
Nerual Network 

Reinforcement Learning :

Hypothesis testing ( t-test, z-test, ANOVA, sign-test)



==========================================================================================================================
