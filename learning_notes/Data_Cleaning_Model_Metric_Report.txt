Data Cleaning (with Pandas)

===========================================================================================================================
Null Value:

===========================================================================================================================
-- If there is very small proportion of N/A data, have a look into why, or just drop those row.(df.drop(<column name>,inplace=True) 
-- If larger proportion : 
(1) impute mean value (or SimpleImputer)
(2) impute mean value according to class ( which class? need domain knowledge)

e.g.
def impute_age(cols):
    Age = cols[0]
    Pclass = cols[1]
    
    if pd.isnull(Age):

        if Pclass == 1:
            return 37

        elif Pclass == 2:
            return 29

        else:
            return 24

    else:
        return Age

df['Age'] = df[['Age','Pclass']].apply(impute_age,axis=1)


-- If very large portion :
just drop the column : df.drop(<column name>,axis=1,inplace=True) // axis = 0 for row, 1 for whole column, default 0


my_imputer = SimpleImputer()
imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))
imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))

===========================================================================================================================
Categorical Variable Handling : 
(1) One-Hot Encoding :
Sex : Male / Female 
sex = pd.get_dummies(df['Sex'],drop_first=True) # makes it numerical , drop_first => avoid duplicate 
df.drop(['Sex'],axis=1,inplace=True) # drop those string based variable 
df = pd.concat([sex],axis=1) # add those numerical column back. 

(2) drop the columns with object type (non-num)
drop_X_train = X_train.select_dtypes(exclude=['object'])
drop_X_valid = X_valid.select_dtypes(exclude=['object'])

(3) LabelEncoding :
label_encoder = LabelEncoder()
for col in object_cols:
    label_X_train[col] = label_encoder.fit_transform(X_train[col])
    label_X_valid[col] = label_encoder.transform(X_valid[col])
Generally One-hot encoding perform best
===========================================================================================================================
Feature Scaling : Mean Normalization : 
x = (xi-mean)/(max-min)
or 
x = (xi-mean)/(standard deviation) -- called standardization, lesser affected by outlier
or just normalize :
x = (x-min)/(max-min)
When to use ?
K-Means,KNN -- distance based algo
PCA -- need variance computation 
NN
GD -- converge faster

===========================================================================================================================
R2_Score (for Linear Regression) :
1-RSS/TSS
ASE : avg standard err
MSE : mean standard error 
RMSE : root mean standard error

===========================================================================================================================
For classification : 
classification_report(y_test,predictions)
True Positive : Predicted yes, infact yes
True Negative : Predicted no, in fact no	
False Positive : Predicted yes, in fact no (Type I error)
False Negative : Predicted no, in fact yes (Type II error)

Note in logistic regression , h's output is p , not 1/0, we just set the decision boundary as p>0.5 by default.


Accuracy : (TP+TN)/Total Trials
Precision : TP/(TP+FP) = true positive / number of predicted positive 
recall : TP/(TP+FN) = true positive / no. of actual positive
F1-score : 2/(1/P+1/R) = 2(PR)/(P+R)
support  : occurrance

In security recognition, we want to open door (predict 1) only when very confident. 
We increase h boundary to predict 1 => higher precision , lower recall (P/Rinverse relationship)
In cancer prediction case, we decrease h's boundary, because very bad when reported no cancer when in fact have cancer. 
=> lower precision, higher recall.

The Metrics to find the "best" P/R combination : find the algo (if we have > 1 algos )with highest F1 score (with beta = 1, P/R same importance )
Can adjust beta for F1 score to tune the importance of P or R. 
beta = 0 => precision 
beta = +inf => recall 

in python classification report 
precision + 1 means when the model say 1, % the model is correct.
recall + 1 means of all 1s , the % which the model can predict 1
===========================================================================================================================


